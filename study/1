1. 기본적인 정리
![1.JPG](../img/1.JPG)
딥러닝: 딥러닝 내부에서 특징추출기와 분류기가 있기 때문에 모든 것이 학습 대상
딥러닝 구성 요소 :  학습단계, 테스트 단계

2. 얕은 신경망의 구조
전결합 계층: 모든 노드가 연결된 계층
얕은 신경망: 입력 계층, 은닉 계층, 출력 계층으로 구성

3. 얕은 신경망을 이용한 분류와 회귀
1)	회귀: 학습 샘플로부터 규칙을 찾아서 연속된 값의 출력을 추정
         (새로운 입력에 대해 적정한 값을 출력할 수 있도록 함)
2)	분류: 입력 값을 분석해서 특정 범주로 구분
! 얕은 신경망의 동작은 출력 계층의 활성 함수에 따라 동작이 바뀜 !

4.	얕은 신경망의 수식적 이해
1)	뉴런의 수학적 표현
![2.JPG](../img/2.JPG)
![3.JPG](../img/3.JPG)
위 식처럼 입력*가중치의 합은 두 벡터의 내적과 같다.
![4.JPG](../img/4.JPG)
a: 활성화 함수, w:가중치 , b: 편향 

2)	전 결합 계층의 수학적 표현
![5.JPG](../img/5.JPG)
![6.JPG](../img/6.JPG)
(출력 개수를 M, 입력 개수를 N이라 가정)
 n*1 행렬을 m만큼 나열하면 n*m 행렬 ->Transpose: m*n 행렬
![7.JPG](../img/7_1.JPG)
위 두 행렬을 곱한다

3) 입력계층
어떤 입력을 받는지가 중요-> 특징 추출 문제(1장 머신 러닝 부분)
![7.JPG](../img/7_2.JPG)

4) 은닉계층
![8.JPG](../img/8.JPG)

5) 출력계층
![9.JPG](../img/9.JPG)

5.	회귀 문제의 이해
1)	단순 선형 회귀
선형 회귀: 학습 데이터를 가장 잘 표현하는 선형식을 찾는 동작 (w, b 찾기)
![10.JPG](../img/10.JPG)
![11.JPG](../img/11.JPG)

2) 다중 선형 회귀
![12.JPG](../img/12.JPG)
![13.JPG](../img/13.JPG)

6. 이진분류
1) 분류
![14.JPG](../img/14.JPG)

2) 로지스틱 회귀
범주형 데이터가 대상
![15.JPG](../img/15.JPG)

3) 시그모이드 함수
![16.JPG](../img/16.JPG)

4) 엔트로피 오차
![17.JPG](../img/17.JPG)
![18.JPG](../img/18.JPG)

5) 다중 로지스틱 회귀의 기하학적 해석
위와 동일

6) 얕은 신경망과 분류 알고리즘
![19.JPG](../img/19.JPG)
